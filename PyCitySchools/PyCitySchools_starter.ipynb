{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyCity Schools Analysis\n",
    "\n",
    "- Your analysis here\n",
    "  \n",
    "  This combined data set allowed us to analyze academic data on different scales: district, school, and grade per subject. The data included 8 charter schools and 7 district schools and district schools were in the majority of higher performing schools compared to charter schools. The passing rate for reading was significantly higher compared to the math passing rate. \n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'PyCitySchools/Resources/schools_complete.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m student_data_to_load \u001b[38;5;241m=\u001b[39m Path(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPyCitySchools/Resources/students_complete.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Read School and Student Data File and store into Pandas DataFrames\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m school_data \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(school_data_to_load)\n\u001b[1;32m     11\u001b[0m student_data \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(student_data_to_load)\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# Combine the data into a single dataset.  \u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/dev/lib/python3.11/site-packages/pandas/io/parsers/readers.py:948\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    936\u001b[0m     dialect,\n\u001b[1;32m    937\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    944\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m    945\u001b[0m )\n\u001b[1;32m    946\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 948\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[0;32m~/anaconda3/envs/dev/lib/python3.11/site-packages/pandas/io/parsers/readers.py:611\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    608\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    610\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 611\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m    613\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    614\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/anaconda3/envs/dev/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1448\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1445\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1447\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1448\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
      "File \u001b[0;32m~/anaconda3/envs/dev/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1705\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1703\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1704\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1705\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[1;32m   1706\u001b[0m     f,\n\u001b[1;32m   1707\u001b[0m     mode,\n\u001b[1;32m   1708\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1709\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1710\u001b[0m     memory_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory_map\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[1;32m   1711\u001b[0m     is_text\u001b[38;5;241m=\u001b[39mis_text,\n\u001b[1;32m   1712\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding_errors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1713\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1714\u001b[0m )\n\u001b[1;32m   1715\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1716\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/anaconda3/envs/dev/lib/python3.11/site-packages/pandas/io/common.py:863\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    858\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    859\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    860\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    861\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    862\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 863\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[1;32m    864\u001b[0m             handle,\n\u001b[1;32m    865\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[1;32m    866\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[1;32m    867\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[1;32m    868\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    869\u001b[0m         )\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    871\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    872\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'PyCitySchools/Resources/schools_complete.csv'"
     ]
    }
   ],
   "source": [
    "# Dependencies and Setup\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# File to Load (Remember to Change These)\n",
    "school_data_to_load = Path('PyCitySchools/Resources/schools_complete.csv')\n",
    "student_data_to_load = Path('PyCitySchools/Resources/students_complete.csv')\n",
    "\n",
    "# Read School and Student Data File and store into Pandas DataFrames\n",
    "school_data = pd.read_csv(school_data_to_load)\n",
    "student_data = pd.read_csv(student_data_to_load)\n",
    "\n",
    "# Combine the data into a single dataset.  \n",
    "school_data_complete = pd.merge(student_data, school_data, how=\"left\", on=[\"school_name\", \"school_name\"])\n",
    "print(school_data_complete.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the total number of unique schools\n",
    "school_count = school_data_complete[\"school_name\"].nunique()\n",
    "school_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## District Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the total budget\n",
    "total_budget = school_data_complete[\"budget\"].sum()\n",
    "total_budget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the total number of students\n",
    "student_count = school_data_complete[\"Student ID\"].count()\n",
    "student_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the average (mean) reading score\n",
    "average_reading_score = school_data_complete[\"reading_score\"].mean()\n",
    "average_reading_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the average (mean) math score\n",
    "average_math_score = school_data_complete[\"math_score\"].mean()\n",
    "average_math_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the percentage of students who passed reading (hint: look at how the math percentage was calculated)  \n",
    "passing_reading_count = school_data_complete[(school_data_complete[\"reading_score\"] >= 70)].count()[\"student_name\"]\n",
    "passing_reading_percentage = passing_reading_count / float(student_count)*100\n",
    "passing_reading_percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the following to calculate the percentage of students who passed math (math scores greather than or equal to 70)\n",
    "passing_math_count = school_data_complete[(school_data_complete[\"math_score\"] >= 70)].count()[\"student_name\"]\n",
    "passing_math_percentage = passing_math_count / float(student_count) * 100\n",
    "passing_math_percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a high-level snapshot of the district's key metrics in a DataFrame\n",
    "district_summary = pd.DataFrame({\"Total Schools\":[school_count], \"Total Students\":[student_count],\"Total Budget\":[total_budget],\n",
    "                                \"Average Math Score\":[average_math_score], \"Average Reading Score\":[average_reading_score], \"% Passing Math\":[passing_math_percentage],\n",
    "                                \"% Passing Reading\":[passing_reading_percentage],\"% Overall Passing Rate\":[overall_passing_rate]})\n",
    "\n",
    "# Formatting\n",
    "district_summary[\"Total Students\"] = district_summary[\"Total Students\"].map(\"{:,}\".format)\n",
    "district_summary[\"Total Budget\"] = district_summary[\"Total Budget\"].map(\"${:,.2f}\".format)\n",
    "\n",
    "# Display the DataFrame\n",
    "district_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the following to calculate the percentage of students that passed math and reading\n",
    "passing_math_reading_count = school_data_complete[\n",
    "    (school_data_complete[\"math_score\"] >= 70) & (school_data_complete[\"reading_score\"] >= 70)\n",
    "].count()[\"student_name\"]\n",
    "overall_passing_rate = passing_math_reading_count /  float(student_count) * 100\n",
    "overall_passing_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the code provided to select all of the school types\n",
    "school_types = school_data.set_index([\"school_name\"])[\"type\"]\n",
    "school_types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## School Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the total school budget and per capita spending per school\n",
    "per_school_budget = school_data_complete.groupby([\"school_name\"])[\"budget\"].mean()\n",
    "per_school_capita = per_school_budget/per_school_counts\n",
    "per_school_budget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the total student count per school\n",
    "per_school_counts = school_data_complete[\"school_name\"].value_counts()\n",
    "per_school_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the number of students per school with math scores of 70 or higher\n",
    "students_passing_math = school_data_complete[(school_data_complete[\"math_score\"] >= 70)]\n",
    "school_students_passing_math = students_passing_math.groupby([\"school_name\"]).size()\n",
    "school_students_passing_math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Calculate the average test scores per school\n",
    "per_school_math = school_data_complete.groupby([\"school_name\"])[\"math_score\"].mean()\n",
    "per_school_reading = school_data_complete.groupby([\"school_name\"])[\"reading_score\"].mean()\n",
    "per_school_math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the provided code to calculate the number of students per school that passed both math and reading with scores of 70 or higher\n",
    "students_passing_math_and_reading = school_data_complete[\n",
    "    (school_data_complete[\"reading_score\"] >= 70) & (school_data_complete[\"math_score\"] >= 70)]\n",
    "school_students_passing_math_and_reading = students_passing_math_and_reading.groupby([\"school_name\"]).size()\n",
    "school_students_passing_math_and_reading "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the number of students per school with reading scores of 70 or higher\n",
    "students_passing_reading =school_data_complete[(school_data_complete[\"reading_score\"] >= 70)]\n",
    "school_students_passing_reading = students_passing_reading.groupby([\"school_name\"]).size()\n",
    "school_students_passing_reading                              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the provided code to calculate the passing rates\n",
    "per_school_passing_math = school_students_passing_math / per_school_counts * 100\n",
    "per_school_passing_reading = school_students_passing_reading / per_school_counts * 100\n",
    "overall_passing_rate = school_students_passing_math_and_reading / per_school_counts * 100\n",
    "overall_passing_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame called `per_school_summary` with columns for the calculations above.\n",
    "per_school_summary = pd.DataFrame(({\"School Type\":school_types,\n",
    "                                    \"Total Students\":per_school_counts,\n",
    "                                    \"Total School Budget\":per_school_budget,\n",
    "                                    \"Per Student Budget\":per_school_capita,\n",
    "                                    \"Average Math Score\":average_math_score,\n",
    "                                    \"Average Reading Score\":average_reading_score,\n",
    "                                    \"% Math Passing Rate\":passing_math_percentage,\n",
    "                                    \"% Reading Passing Rate\":passing_reading_percentage,\n",
    "                                    \"% Overall Passing Rate\":overall_passing_rate}))\n",
    "# Formatting\n",
    "per_school_summary[\"Total School Budget\"] = per_school_summary[\"Total School Budget\"].map(\"${:,.2f}\".format)\n",
    "per_school_summary[\"Per Student Budget\"] = per_school_summary[\"Per Student Budget\"].map(\"${:,.2f}\".format)\n",
    "\n",
    "# Display the DataFrame\n",
    "per_school_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bottom Performing Schools (By % Overall Passing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort the schools by `% Overall Passing` in descending order and display the top 5 rows.\n",
    "top_schools =per_school_summary.sort_values([\"% Overall Passing Rate\"], ascending=False)\n",
    "top_schools.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Highest-Performing Schools (by % Overall Passing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort the schools by `% Overall Passing` in ascending order and display the top 5 rows.\n",
    "bottom_schools =per_school_summary.sort_values([\"% Overall Passing Rate\"],ascending=True)\n",
    "bottom_schools.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Math Scores by Grade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the code provided to separate the data by grade\n",
    "ninth_graders = school_data_complete[(school_data_complete[\"grade\"] == \"9th\")]\n",
    "tenth_graders = school_data_complete[(school_data_complete[\"grade\"] == \"10th\")]\n",
    "eleventh_graders = school_data_complete[(school_data_complete[\"grade\"] == \"11th\")]\n",
    "twelfth_graders = school_data_complete[(school_data_complete[\"grade\"] == \"12th\")]\n",
    "\n",
    "# Group by `school_name` and take the mean of the `math_score` column for each.\n",
    "ninth_grade_math_scores = school_data_complete.groupby([\"school_name\"])[\"math_score\"].mean()\n",
    "tenth_grader_math_scores = school_data_complete.groupby([\"school_name\"])[\"math_score\"].mean()\n",
    "eleventh_grader_math_scores = school_data_complete.groupby([\"school_name\"])[\"math_score\"].mean()\n",
    "twelfth_grader_math_scores = school_data_complete.groupby([\"school_name\"])[\"math_score\"].mean()\n",
    "\n",
    "# Combine each of the scores above into single DataFrame called `math_scores_by_grade`\n",
    "math_scores_by_grade =  pd.DataFrame(({\"9th\":ninth_grade_math_scores,\n",
    "                                    \"10th\":tenth_grader_math_scores,\n",
    "                                    \"11th\":eleventh_grader_math_scores,\n",
    "                                    \"12th\":twelfth_grader_math_scores}))\n",
    "\n",
    "# Minor data wrangling\n",
    "math_scores_by_grade.index.name = None\n",
    "\n",
    "# Display the DataFrame\n",
    "math_scores_by_grade"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading Score by Grade "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the code provided to separate the data by grade\n",
    "ninth_graders = school_data_complete[(school_data_complete[\"grade\"] == \"9th\")]\n",
    "tenth_graders = school_data_complete[(school_data_complete[\"grade\"] == \"10th\")]\n",
    "eleventh_graders = school_data_complete[(school_data_complete[\"grade\"] == \"11th\")]\n",
    "twelfth_graders = school_data_complete[(school_data_complete[\"grade\"] == \"12th\")]\n",
    "\n",
    "# Group by `school_name` and take the mean of the the `reading_score` column for each.\n",
    "ninth_grade_reading_scores = school_data_complete.groupby([\"school_name\"])[\"reading_score\"].mean()\n",
    "tenth_grader_reading_scores = school_data_complete.groupby([\"school_name\"])[\"reading_score\"].mean()\n",
    "eleventh_grader_reading_scores = school_data_complete.groupby([\"school_name\"])[\"reading_score\"].mean()\n",
    "twelfth_grader_reading_scores = school_data_complete.groupby([\"school_name\"])[\"reading_score\"].mean()\n",
    "\n",
    "# Combine each of the scores above into single DataFrame called `reading_scores_by_grade`\n",
    "reading_scores_by_grade = pd.DataFrame(({\"9th\":ninth_grade_reading_scores,\n",
    "                                    \"10th\":tenth_grader_reading_scores,\n",
    "                                    \"11th\":eleventh_grader_reading_scores,\n",
    "                                    \"12th\":twelfth_grader_reading_scores}))\n",
    "\n",
    "# Minor data wrangling\n",
    "reading_scores_by_grade = reading_scores_by_grade[[\"9th\", \"10th\", \"11th\", \"12th\"]]\n",
    "reading_scores_by_grade.index.name = None\n",
    "\n",
    "# Display the DataFrame\n",
    "reading_scores_by_grade"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scores by School Spending"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Establish the bins \n",
    "spending_bins = [0, 585, 630, 645, 680]\n",
    "labels = [\"<$585\", \"$585-630\", \"$630-645\", \"$645-680\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a copy of the school summary since it has the \"Per Student Budget\" \n",
    "school_spending_df = per_school_summary.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use `pd.cut` to categorize spending based on the bins.\n",
    "school_spending_df[\"Spending Ranges (Per Student)\"] = pd.cut(per_school_summary[\"Total School Budget\"]/per_school_summary[\"Total Students\"]\n",
    "                                                    ,bins , labels=group_names)\n",
    "school_spending_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Calculate averages for the desired columns. \n",
    "spending_math_scores = school_spending_df.groupby([\"Spending Ranges (Per Student)\"])[\"Average Math Score\"].mean()\n",
    "spending_reading_scores = school_spending_df.groupby([\"Spending Ranges (Per Student)\"])[\"Average Reading Score\"].mean()\n",
    "spending_passing_math = school_spending_df.groupby([\"Spending Ranges (Per Student)\"])[\"% Passing Math\"].mean()\n",
    "spending_passing_reading = school_spending_df.groupby([\"Spending Ranges (Per Student)\"])[\"% Passing Reading\"].mean()\n",
    "overall_passing_spending = school_spending_df.groupby([\"Spending Ranges (Per Student)\"])[\"% Overall Passing\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assemble into DataFrame\n",
    "spending_summary = \n",
    "\n",
    "# Display results\n",
    "spending_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scores by School Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Establish the bins.\n",
    "size_bins = [0, 1000, 2000, 5000]\n",
    "labels = [\"Small (<1000)\", \"Medium (1000-2000)\", \"Large (2000-5000)\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorize the spending based on the bins\n",
    "# Use `pd.cut` on the \"Total Students\" column of the `per_school_summary` DataFrame.\n",
    "\n",
    "per_school_summary[\"School Size\"] = \n",
    "per_school_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate averages for the desired columns. \n",
    "size_math_scores = per_school_summary.groupby([\"School Size\"])[\"Average Math Score\"].mean()\n",
    "size_reading_scores = per_school_summary.groupby([\"School Size\"])[\"Average Reading Score\"].mean()\n",
    "size_passing_math = per_school_summary.groupby([\"School Size\"])[\"% Passing Math\"].mean()\n",
    "size_passing_reading = per_school_summary.groupby([\"School Size\"])[\"% Passing Reading\"].mean()\n",
    "size_overall_passing = per_school_summary.groupby([\"School Size\"])[\"% Overall Passing\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create a DataFrame called `size_summary` that breaks down school performance based on school size (small, medium, or large).\n",
    "# Use the scores above to create a new DataFrame called `size_summary`\n",
    "size_summary = pd.size_summary\n",
    "\n",
    "# Display results\n",
    "size_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scores by School Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group the per_school_summary DataFrame by \"School Type\" and average the results.\n",
    "average_math_score_by_type = per_school_summary.groupby([\"School Type\"])[\"Average Math Score\"].mean()\n",
    "average_reading_score_by_type = per_school_summary.groupby([\"School Type\"])[\"Average Reading Score\"].mean()\n",
    "average_percent_passing_math_by_type = per_school_summary.groupby([\"School Type\"])[\"% Passing Math\"].mean()\n",
    "average_percent_passing_reading_by_type = per_school_summary.groupby([\"School Type\"])[\"% Passing Reading\"].mean()\n",
    "average_percent_overall_passing_by_type = per_school_summary.groupby([\"School Type\"])[\"% Overall Passing\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assemble the new data by type into a DataFrame called `type_summary`\n",
    "type_summary = pd.type_summary\n",
    "\n",
    "# Display results\n",
    "type_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "nteract": {
   "version": "0.8.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "5384d77d82de63fd599f73e77f9ec786e7719288bf80a29ec0288c670ac3cf32"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
